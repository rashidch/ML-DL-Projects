{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-657032c8ad2a>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Shape of Train_x: (50000, 28, 28, 1)\n",
      "Shape of Train_y: (50000, 10)\n",
      ".......................................\n",
      "Shape of Validation_x: (5000, 28, 28, 1)\n",
      "Shape of Validation_y: (5000, 10)\n",
      ".......................................\n",
      "Shape of Test_x: (10000, 28, 28, 1)\n",
      "Shape of Test_y: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "train_data = mnist.train.images\n",
    "train_y = mnist.train.labels\n",
    "test_data  = mnist.test.images\n",
    "test_y = mnist.test.labels    \n",
    "\n",
    "#reshape the train_data and test_data\n",
    "def reshape_data(train_data, test_data):\n",
    "    \n",
    "    #train_data =(train_data-(255/2.0))/255\n",
    "    #train_x = train_data.reshape(55000,28,28,1)\n",
    "    train_x = (train_data>0).reshape(55000,28,28,1).astype(np.uint8)*255\n",
    "    \n",
    "    \n",
    "    test_x  = (test_data>0).reshape(10000,28,28,1).astype(np.uint8)*255\n",
    "    #test_data =(test_data-(255/2.0))/255\n",
    "    #test_x   = test_data.reshape(10000,28,28,1)\n",
    "    \n",
    "    return train_x, test_x\n",
    "\n",
    "# split train_data into train_x and validation_x\n",
    "train_x, test_x = reshape_data(train_data, test_data)\n",
    "validation_x   = train_x[:5000, ...]\n",
    "validation_y = train_y[:5000]\n",
    "train_x = train_x[5000:, ...]\n",
    "train_y = train_y[5000:]\n",
    "\n",
    "print(\"Shape of Train_x:\", train_x.shape)\n",
    "print(\"Shape of Train_y:\", train_y.shape)\n",
    "print(\".......................................\")\n",
    "print(\"Shape of Validation_x:\", validation_x.shape)\n",
    "print(\"Shape of Validation_y:\", validation_y.shape)\n",
    "print(\".......................................\")\n",
    "print(\"Shape of Test_x:\", test_x.shape)\n",
    "print(\"Shape of Test_y:\",test_y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # variables for input and output \n",
    "def create_placeholder(H,W,C,y):\n",
    "    \n",
    "    train_x = tf.placeholder(tf.float32, shape=(None, H,W,C))\n",
    "    train_y = tf.placeholder(tf.float32, shape=(None, y))\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "# weight initialization\n",
    "def weight_variable(shape, name = None):\n",
    "    \n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "# bias initialization\n",
    "def bias_variable(shape, name = None):\n",
    "    \n",
    "    initial = tf.constant(0.1, shape=shape) \n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "# 2D convolution\n",
    "def conv2d(x, W, name = None):\n",
    "    \n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name = name)\n",
    "\n",
    "# max pooling\n",
    "def max_pool_2x2(x, name = None):\n",
    "    \n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,Y):\n",
    "    \n",
    "    cache=dict()\n",
    "    \n",
    "    # 1.layer: convolution + max pooling\n",
    "    W_conv1_tf = weight_variable([5,5,1,32], name = 'W_conv1_tf') # (5,5,1,32)\n",
    "    b_conv1_tf = bias_variable([32], name = 'b_conv1_tf') # (32)\n",
    "    h_conv1_tf = tf.nn.relu(conv2d(X,W_conv1_tf) + b_conv1_tf, name = 'h_conv1_tf') # (.,28,28,32)\n",
    "    h_pool1_tf = max_pool_2x2(h_conv1_tf, name = 'h_pool1_tf') # (.,14,14,32)\n",
    "    \n",
    "    cache['h_conv1_tf']=h_conv1_tf\n",
    "    cache['h_pool1_tf']= h_pool1_tf\n",
    "    \n",
    "    print(h_pool1_tf.shape)\n",
    "    \n",
    "    # 2.layer: convolution + max pooling\n",
    "    W_conv2_tf = weight_variable([5,5,32,32],name = 'W_conv2_tf')\n",
    "    b_conv2_tf = bias_variable([32], name = 'b_conv2_tf')\n",
    "    h_conv2_tf = tf.nn.relu(conv2d(h_pool1_tf, W_conv2_tf) + b_conv2_tf, name ='h_conv2_tf') #(.,14,14,32)\n",
    "    h_pool2_tf = max_pool_2x2(h_conv2_tf, name = 'h_pool2_tf') #(.,7,7,32)\n",
    "    \n",
    "    cache['h_conv2_tf']=h_conv2_tf\n",
    "    cache['h_pool2_tf']= h_pool2_tf\n",
    "    \n",
    "    print(h_pool2_tf.shape)\n",
    "    \n",
    "    W_conv3_tf = weight_variable([3,3,32,64], name = 'W_conv3_tf')\n",
    "    b_conv3_tf = bias_variable([64], name = 'b_conv3_tf')\n",
    "    h_conv3_tf = tf.nn.relu(conv2d(h_pool2_tf, W_conv3_tf) + b_conv3_tf, name = 'h_conv3_tf') #(.,7,7,32)\n",
    "    h_pool3_tf = max_pool_2x2(h_conv3_tf, name = 'h_pool3_tf') # (.,4,4,64)\n",
    "    \n",
    "    cache['h_conv3_tf']=h_conv3_tf\n",
    "    cache['h_pool3_tf']= h_pool3_tf\n",
    "    \n",
    "    print(h_pool3_tf.shape)\n",
    "    \n",
    "    # 4.layer: fully connected\n",
    "    W_fc1_tf = weight_variable([4*4*64,500], name = 'W_fc1_tf') # (4*4*32, 1024)\n",
    "    b_fc1_tf = bias_variable([500], name = 'b_fc1_tf') # (1024)\n",
    "    h_pool3_flat_tf = tf.reshape(h_pool3_tf, [-1,4*4*64], name = 'h_pool3_flat_tf') # (.,1024)\n",
    "    h_fc1_tf = tf.nn.relu(tf.matmul(h_pool3_flat_tf,W_fc1_tf) + b_fc1_tf, name = 'h_fc1_tf') # (.,1024)\n",
    "    \n",
    "    cache['h_fc1_tf']=h_fc1_tf\n",
    "    \n",
    "    print(h_fc1_tf.shape)\n",
    "    \n",
    "    # 5.layer: fully connected\n",
    "    W_fc2_tf = weight_variable([500, 10], name = 'W_fc2_tf')\n",
    "    b_fc2_tf = bias_variable([10], name = 'b_fc2_tf')\n",
    "    z_pred_tf = tf.add(tf.matmul(h_fc1_tf,W_fc2_tf), b_fc2_tf, name = 'z_pred_tf')# => (.,10)\n",
    "    \n",
    "    cache['z_pred_tf']= z_pred_tf\n",
    "    \n",
    "    \n",
    "    # cost function\n",
    "    cross_entropy_tf = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y , logits=z_pred_tf), name = 'cross_entropy_tf')\n",
    "    \n",
    "    #predicted probabilities in one-hot encoding\n",
    "    y_pred_proba_tf = tf.nn.softmax(z_pred_tf, name='y_pred_proba_tf') \n",
    "    \n",
    "    return cross_entropy_tf,  y_pred_proba_tf, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    \n",
    "    m = X.shape[0]                                           # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "   \n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_featuremap(sess,test_x,test_y,X,Y,cache,n):\n",
    "           \n",
    "            \n",
    "            reshaped_x = np.reshape(test_x[n],(1,28,28,1))\n",
    "            reshaped_y = np.reshape(test_y[n],(1,10))\n",
    "            feed_dict = {X: reshaped_x,Y: reshaped_y}\n",
    "            \n",
    "            h_conv1_tf = cache['h_conv1_tf']\n",
    "          \n",
    "            h_pool1_tf = cache['h_pool1_tf']\n",
    "            h_conv2_tf = cache['h_conv2_tf']\n",
    "            h_pool2_tf = cache['h_pool2_tf']\n",
    "            h_conv3_tf = cache['h_conv3_tf']\n",
    "            h_pool3_tf = cache['h_pool3_tf']\n",
    "            h_fc1_tf   = cache['h_fc1_tf']\n",
    "            \n",
    "            print('calculate feature map')\n",
    "            feature_map1 = h_conv1_tf.eval(session=sess, feed_dict=feed_dict)\n",
    "            print(feature_map1.shape)\n",
    "            feature_map2 = h_conv2_tf.eval(session=sess, feed_dict=feed_dict)\n",
    "            print(feature_map2.shape)\n",
    "            feature_map3 = h_conv3_tf.eval(session=sess, feed_dict=feed_dict)\n",
    "            print(feature_map3.shape)\n",
    "            \n",
    "         \n",
    "            plt.imshow(test_x[n].reshape(28,28),cmap='gray')\n",
    "            plt.title('Feature Map Image')\n",
    "            plt.savefig('Feature Map Image')\n",
    "            \n",
    "            fm=np.reshape(feature_map1,(28,28,32))\n",
    "            for i in range(9):\n",
    "                plt.subplot(3,3,i+1)\n",
    "                _=plt.imshow(fm[:,:,i],cmap='gray')\n",
    "                \n",
    "                plt.axis('off')\n",
    "                plt.savefig('featuremap1',dpi=1000)\n",
    "                \n",
    "            \n",
    "            \n",
    "            fm=np.reshape(feature_map2,(14,14,32))\n",
    "            for i in range(3):\n",
    "                plt.subplot(3,3,i+1)\n",
    "                _=plt.imshow(fm[:,:,i],cmap='gray')\n",
    "                \n",
    "                plt.axis('off')\n",
    "                plt.savefig('featuremap2',dpi=1000)\n",
    "                \n",
    "            \n",
    "            \n",
    "            fm=np.reshape(feature_map3,(7,7,64))\n",
    "            for i in range(9):\n",
    "                plt.subplot(3,3,i+1)\n",
    "                _=plt.imshow(fm[:,:,i],cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.savefig('featuremap3',dpi=1000)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_x, train_y, valid_x,valid_y, test_x, test_y, learning_rate = 0.0001, num_epochs = 50, minibatch_size = 16, print_cost = True):\n",
    "    \n",
    "    \n",
    "    ops.reset_default_graph()  \n",
    "    \n",
    "    (m, H, W, C) = train_x.shape             \n",
    "    n_y = train_y.shape[1]                            \n",
    "    train_losses = [] \n",
    "    \n",
    "    train_acc = []\n",
    "    valid_acc = []\n",
    "    test_acc  = []\n",
    "    weights= dict()\n",
    "    \n",
    "    cache_layers=dict()\n",
    "    \n",
    "    seed = 3  \n",
    "    X,Y = create_placeholder(H, W, C, n_y)\n",
    "    loss, fc4, cache_layers  = forward_propagation(X, Y)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(train_x, train_y, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # Run the session to execute the optimizer and the cost on minibatch\n",
    "                _ , temp_cost = sess.run([optimizer,loss], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost of training data after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                train_losses.append(minibatch_cost)\n",
    "\n",
    "                \n",
    "        \n",
    "\n",
    "            # Calculate the correct predictions\n",
    "            predict_op = tf.argmax(fc4, 1)\n",
    "            correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "            # Calculate accuracy on the test set\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "           \n",
    "        \n",
    "            \n",
    "            train_accuracy = 0\n",
    "            valid_accuracy = 0\n",
    "            test_accuracy =  0\n",
    "            \n",
    "            #calculate training accuracy\n",
    "            for minibatch in minibatches:\n",
    "            \n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                temp_accuracy = accuracy.eval({X: minibatch_X, Y: minibatch_Y})\n",
    "                train_accuracy += temp_accuracy / num_minibatches\n",
    "            \n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                train_acc.append(train_accuracy)\n",
    "       \n",
    "            #calculate validation accuracy\n",
    "            \n",
    "            valid_accuracy = accuracy.eval({X: valid_x, Y: valid_y})\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                valid_acc.append(valid_accuracy)\n",
    "                \n",
    "             #calculate test accuracy\n",
    "            test_accuracy = accuracy.eval({X: test_x, Y: test_y})\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                test_acc.append(test_accuracy)\n",
    "        \n",
    "        #extract feature_maps\n",
    "        get_featuremap(sess,test_x, test_y, X,Y, cache_layers,100)\n",
    "        \n",
    "        # extract trained weights and biases\n",
    "        \n",
    "        W_conv1  = sess.run('W_conv1_tf:0')\n",
    "        W_conv2  = sess.run('W_conv2_tf:0')\n",
    "        W_conv3  = sess.run('W_conv3_tf:0')\n",
    "        W_fc1    = sess.run('W_fc1_tf:0')\n",
    "        W_output = sess.run('W_fc2_tf:0')\n",
    "        \n",
    "        b_conv1  = sess.run('b_conv1_tf:0')\n",
    "        b_conv2  = sess.run('b_conv2_tf:0')\n",
    "        b_conv3  = sess.run('b_conv3_tf:0')\n",
    "        b_fc1    = sess.run('b_fc1_tf:0')\n",
    "        b_output = sess.run('b_fc2_tf:0')\n",
    "        \n",
    "        weights['W_conv1']=W_conv1\n",
    "        weights['W_conv2']=W_conv2\n",
    "        weights['W_conv3']=W_conv3\n",
    "        weights['W_fc1']=W_fc1\n",
    "        weights['W_output']=W_output\n",
    "        \n",
    "        weights['b_conv1']=b_conv1\n",
    "        weights['b_conv2']=b_conv2\n",
    "        weights['b_conv3']=b_conv3\n",
    "        weights['b_fc1']=b_fc1\n",
    "        weights['b_output']=b_output\n",
    "        \n",
    "        #print accuracies\n",
    "       \n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Validation Accuracy:\", valid_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \n",
    "        #Visualize missclassified and correctly classified images\n",
    "        \n",
    "        pred_y= fc4.eval(feed_dict = {X:test_x})\n",
    "        y_valid_pred_label = np.argmax(pred_y,1)\n",
    "        y_valid_label = np.argmax(test_y,1)\n",
    "        y_val_false_index = []\n",
    "        y_val_true_index = []\n",
    "        \n",
    "       \n",
    "        \n",
    "        for i in range(y_valid_label.shape[0]):\n",
    "            if y_valid_pred_label[i] != y_valid_label[i]:\n",
    "                y_val_false_index.append(i)\n",
    "\n",
    "        print('# False predictions: ', len(y_val_false_index),'out of', len(test_y))\n",
    "        \n",
    "        plt.figure(figsize=(10,15))\n",
    "        for j in range(0,1):\n",
    "            for i in range(0,4):\n",
    "                if j*10+i<len(y_val_false_index):\n",
    "                    plt.subplot(1,4,j*10+i+1)\n",
    "                    plt.title('label:'+str(y_valid_label[y_val_false_index[j*10+i]])+'  pred:'+\n",
    "                               str(y_valid_pred_label[y_val_false_index[j*10+i]]))\n",
    "                    plt.imshow(test_x[y_val_false_index[j*10+i]].reshape(28,28),cmap='gray') \n",
    "                    plt.savefig('miss_classfied')\n",
    "        \n",
    "        for k in range(y_valid_label.shape[0]):\n",
    "            if y_valid_pred_label[k] == y_valid_label[k]:\n",
    "                y_val_true_index.append(k)\n",
    "                \n",
    "        print('# True predictions: ', len(y_val_true_index),'out of', len(test_y))\n",
    "        \n",
    "        plt.figure(figsize=(10,15))\n",
    "        for j in range(0,1):\n",
    "            for i in range(0,4):\n",
    "                if j*10+i<len(y_val_false_index):\n",
    "                    plt.subplot(1,4,j*10+i+1)\n",
    "                    plt.title('label:'+str(y_valid_label[y_val_true_index[j*10+i]])+'  pred:'+str(y_valid_pred_label[y_val_true_index[j*10+i]]))\n",
    "                    plt.imshow(test_x[y_val_true_index[j*10+i]].reshape(28,28),cmap='gray') \n",
    "                    plt.savefig('Correct_classified')\n",
    "     \n",
    "        #get_featuremap(sess,test_x, test_y, X,Y, cache_layers,'miss',y_val_false_index[10])\n",
    "        #get_featuremap(sess,test_x, test_y, X,Y, cache_layers,'Correct',y_val_true_index[10])\n",
    "        \n",
    "        \n",
    "        return train_acc, valid_acc, test_acc, train_losses,weights,fc4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 4, 4, 64)\n",
      "(?, 500)\n",
      "Cost of training data after epoch 0: 11.460508\n",
      "Cost of training data after epoch 5: 0.302956\n",
      "Cost of training data after epoch 10: 0.108857\n",
      "Cost of training data after epoch 15: 0.061861\n",
      "Cost of training data after epoch 20: 0.040127\n",
      "Cost of training data after epoch 25: 0.033699\n",
      "Cost of training data after epoch 30: 0.038021\n",
      "Cost of training data after epoch 35: 0.023798\n",
      "Cost of training data after epoch 40: 0.020580\n",
      "Cost of training data after epoch 45: 0.020994\n",
      "calculate feature map\n",
      "(1, 28, 28, 32)\n",
      "(1, 14, 14, 32)\n",
      "(1, 7, 7, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashid Ali\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9989599999999651\n",
      "Validation Accuracy: 0.9758\n",
      "Test Accuracy: 0.9822\n",
      "# False predictions:  178 out of 10000\n",
      "# True predictions:  9822 out of 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x279fba37630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x279badebe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27a7c4355f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc,valid_acc,test_acc,train_losses,weights,fc4 = model(train_x, train_y, validation_x, validation_y, test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(np.squeeze(train_losses), 'g',label='Cross entropy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title(\"Learning Curve\")\n",
    "#plt.ylim(ymax = 28, ymin = 0.0001)\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('Learning Curve')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(train_acc)), train_acc,'-b', label='Training Accuracy')\n",
    "plt.plot(np.arange(0,len(valid_acc)), valid_acc,'-g', label='Validation Accuracy')\n",
    "plt.plot(np.arange(0,len(test_acc)), test_acc,'-r', label='Test Accuracy')\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "plt.ylim(ymax = 1.00, ymin = 0.92)\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.xlabel('Iteration')\n",
    "plt.savefig('Training Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution of weights and biases\n",
    "W_conv1 =weights['W_conv1']\n",
    "W_conv2 =weights['W_conv2']\n",
    "W_conv3 =weights['W_conv3']\n",
    "W_fc1   =weights['W_fc1']\n",
    "W_output=weights['W_output']\n",
    "        \n",
    "b_conv1 =weights['b_conv1']\n",
    "b_conv2 =weights['b_conv2']\n",
    "b_conv3 =weights['b_conv3']\n",
    "b_fc1   =weights['b_fc1']\n",
    "b_output=weights['b_output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10, 5));\n",
    "#plt.subplot(1,2,1);\n",
    "#num_bins=10\n",
    "W_conv1=W_conv1.reshape((25, 32))\n",
    "plt.hist(W_conv1)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of Conv1')\n",
    "plt.savefig('Histogram of Conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2=W_conv2.reshape((25, 1024))\n",
    "plt.hist(W_conv2)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of Conv2')\n",
    "plt.savefig('Histogram of Conv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(1,2,2)\n",
    "plt.hist(W_fc1)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of dense1')\n",
    "plt.savefig('Histogram of dense1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(1,2,2)\n",
    "plt.hist(W_output)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of output')\n",
    "plt.savefig('Histogram of output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wb=tf.trainable_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m, H, W, C) = train_x.shape             \n",
    "n_y = train_y.shape[1] \n",
    "    \n",
    "X,Y = create_placeholder(H, W, C, n_y)\n",
    "loss, fc4  = forward_propagation(X, Y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    w=sess.run('h_conv1_tf:0')\n",
    "    #print(w)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def getActivations(layer,stimuli):\n",
    "        units = sess.run(layer,feed_dict={X:np.reshape(stimuli,[1,784],order='F')})\n",
    "        plotNNFilter(units)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNNFilter(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageToUse = mnist.test.images[0]\n",
    "plt.imshow(np.reshape(imageToUse,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
