{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Shape of Train_x: (50000, 28, 28, 1)\n",
      "Shape of Train_y: (50000, 10)\n",
      ".......................................\n",
      "Shape of Validation_x: (5000, 28, 28, 1)\n",
      "Shape of Validation_y: (5000, 10)\n",
      ".......................................\n",
      "Shape of Test_x: (10000, 28, 28, 1)\n",
      "Shape of Test_y: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "train_data = mnist.train.images\n",
    "train_y = mnist.train.labels\n",
    "test_data  = mnist.test.images\n",
    "test_y = mnist.test.labels    \n",
    "\n",
    "#reshape the train_data and test_data\n",
    "def reshape_data(train_data, test_data):\n",
    "    \n",
    "    train_x = (train_data>0).reshape(55000,28,28,1).astype(np.uint8)*255\n",
    "    test_x  = (test_data>0).reshape(10000,28,28,1).astype(np.uint8)*255\n",
    "\n",
    "    return train_x, test_x\n",
    "\n",
    "# split train_data into train_x and validation_x\n",
    "train_x, test_x = reshape_data(train_data, test_data)\n",
    "validation_x   = train_x[:5000, ...]\n",
    "validation_y = train_y[:5000]\n",
    "train_x = train_x[5000:, ...]\n",
    "train_y = train_y[5000:]\n",
    "\n",
    "print(\"Shape of Train_x:\", train_x.shape)\n",
    "print(\"Shape of Train_y:\", train_y.shape)\n",
    "print(\".......................................\")\n",
    "print(\"Shape of Validation_x:\", validation_x.shape)\n",
    "print(\"Shape of Validation_y:\", validation_y.shape)\n",
    "print(\".......................................\")\n",
    "print(\"Shape of Test_x:\", test_x.shape)\n",
    "print(\"Shape of Test_y:\",test_y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad),(0,0)),'constant')\n",
    "    \n",
    "    return X_pad\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \n",
    "    s = a_slice_prev*W\n",
    "    Z = np.sum(s)\n",
    "    Z = Z + float(b)\n",
    "\n",
    "    return Z\n",
    "\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "     \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above\n",
    "    n_H = int((n_H_prev - f + 2*pad)/stride + 1)\n",
    "    n_W = int((n_W_prev - f + 2*pad)/stride + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros.\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]                  # Select ith training example's padded activation\n",
    "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" \n",
    "                    vert_start = h*stride\n",
    "                    vert_end = h*stride+f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = w*stride+f\n",
    "                    \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:,:,:,c], float(b[:,:,:,c]))\n",
    "                                        \n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = -54.267488889652185\n",
      "Z[3,2,1] = [ 0.30182753 -0.46297576  0.2171394   1.60236826  0.03968618 -0.01280611\n",
      " -1.87198718 -0.46090325 -1.83461454  0.39634688]\n",
      "cache_conv[0][1][2][3] = [0]\n"
     ]
    }
   ],
   "source": [
    "#Run conv_forward\n",
    "A_prev = train_x[0:10]\n",
    "W = np.random.randn(5,5,1,10)\n",
    "b = np.random.randn(1,1,1,10)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    \n",
    "    for i in range(m):                           # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = h*stride + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = w*stride + f\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "   \n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mode = average\n"
     ]
    }
   ],
   "source": [
    "#Run forward pooling\n",
    "A_prev = train_x[0:10]\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "#print(\"A =\", A)\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "#print(\"A =\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    \n",
    "    # Retrieve information from \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev,pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev,pad)\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
    "        da_prev_pad = dA_prev_pad[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] +=  W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # Set the ith training example's dA_prev to the unpaded da_prev_pad\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 1198.6808962270513\n",
      "dW_mean = -13471979.235181382\n",
      "db_mean = -106364.27822371628\n"
     ]
    }
   ],
   "source": [
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    \n",
    "    mask = (x == np.max(x))\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(2,3)\n",
    "mask = create_mask_from_window(x)\n",
    "print('x = ', x)\n",
    "print(\"mask = \", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \n",
    "    # Retrieve dimensions from shape \n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix\n",
    "    average = dz/(n_H*n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value \n",
    "    a = np.ones((n_H,n_W))*average\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2,2))\n",
    "print('distributed value =', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "        \n",
    "    # Retrieve information from cache\n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = np.shape(A_prev)\n",
    "    m, n_H, n_W, n_C = np.shape(dA)\n",
    "    \n",
    "    # Initialize dA_prev with zeros\n",
    "    dA_prev = np.zeros(np.shape(A_prev))\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select training example from A_prev\n",
    "        a_prev = A_prev[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                   # loop on the vertical axis\n",
    "            for w in range(n_W):               # loop on the horizontal axis\n",
    "                for c in range(n_C):           # loop over the channels (depth)\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        # Use the corners and \"c\" to define the current slice from a_prev \n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        # Create the mask from a_prev_slice (≈1 line)\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) \n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask*dA[i, h*stride, w*stride, c]\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                        # Get the value a from dA\n",
    "                        da = distribute_value(dA,(f,f))\n",
    "                        # Define the shape of the filter as fxf\n",
    "                        shape = (f,f)\n",
    "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. \n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += da[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.013676820545002506\n",
      "dA_prev[1,1] =  [[ 0.20323943]\n",
      " [ 0.20843787]\n",
      " [ 1.02052687]\n",
      " [ 0.95248445]\n",
      " [-0.83611591]\n",
      " [-1.25023392]\n",
      " [ 0.3479425 ]\n",
      " [ 0.9962105 ]\n",
      " [ 0.81944622]\n",
      " [ 2.70618512]\n",
      " [ 1.6319785 ]\n",
      " [-0.30530301]\n",
      " [-0.03323547]\n",
      " [-1.61915887]\n",
      " [-2.37481559]\n",
      " [-0.1170443 ]\n",
      " [ 1.88423947]\n",
      " [ 0.32058087]\n",
      " [-2.73033102]\n",
      " [-2.91917979]\n",
      " [-0.4946884 ]\n",
      " [ 0.25873012]\n",
      " [-1.19970265]\n",
      " [-5.72393947]\n",
      " [-2.76620267]\n",
      " [ 1.95711663]\n",
      " [-4.18259764]\n",
      " [-5.47305323]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_pre = train_x[0:50]\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "dA = np.random.randn(5, 28, 28, 1)\n",
    "\n",
    "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "print()\n",
    "#dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "#print(\"mode = average\")\n",
    "#print('mean of dA = ', np.mean(dA))\n",
    "#print('dA_prev[1,1] = ', dA_prev[1,1]) "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "qO8ng",
   "launcher_item_id": "7XDi8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
