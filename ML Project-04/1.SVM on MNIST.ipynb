{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import pandas as pd \n",
    "os.chdir(r'C:\\Users\\Rashid Ali\\Downloads\\libsvm-3.23\\python')\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(r\"C:\\Users\\Rashid Ali\\Desktop\\MAchine Learning\\Homework-5\\ML_HW5\\X_train.csv\",header=None)\n",
    "train_y = pd.read_csv(r\"C:\\Users\\Rashid Ali\\Desktop\\MAchine Learning\\Homework-5\\ML_HW5\\Y_train.csv\",header=None)\n",
    "test_x  = pd.read_csv(r\"C:\\Users\\Rashid Ali\\Desktop\\MAchine Learning\\Homework-5\\ML_HW5\\X_test.csv\",header=None)\n",
    "test_y  = pd.read_csv(r\"C:\\Users\\Rashid Ali\\Desktop\\MAchine Learning\\Homework-5\\ML_HW5\\Y_test.csv\",header=None)\n",
    "\n",
    "train_x = train_x.values\n",
    "train_y = train_y.values.reshape(5000)\n",
    "test_x  = test_x.values\n",
    "test_y  = test_y.values.reshape(2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel functions\n",
    "\n",
    "-s svm_type : set type of SVM (default 0)\n",
    "\n",
    "    0 -- C-SVC  \n",
    "\n",
    "-t kernel_type : set type of kernel function (default 2)\n",
    "\n",
    "    0 -- linear: u'*v\n",
    "\n",
    "    1 -- polynomial: (gamma*u'*v + coef0)^degree\n",
    "\n",
    "    2 -- radial basis function: exp(-gamma*|u-v|^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Linear Kernel(without setting parameter):\n",
      "train\n",
      "Accuracy = 100% (5000/5000) (classification)\n",
      "\n",
      "test\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "prob = svm_problem(train_y,train_x)\n",
    "print(\"Default Linear Kernel(without setting parameter):\")\n",
    "param = svm_parameter('-s 0 -t 0 -q')\n",
    "m = svm_train(prob,param)\n",
    "\n",
    "print(\"train\")\n",
    "p_lable,p_acc,p_val=svm_predict(train_y, train_x,m)\n",
    "print()\n",
    "print(\"test\")\n",
    "p_lable,p_acc,p_val=svm_predict(test_y, test_x,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Kernel(without setting parameter):\n",
      "train\n",
      "Accuracy = 34.34% (1717/5000) (classification)\n",
      "\n",
      "test\n",
      "Accuracy = 34.68% (867/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "prob = svm_problem(train_y,train_x)\n",
    "print(\"Polynomial Kernel(without setting parameter):\")\n",
    "param = svm_parameter('-s 0 -t 1 -q')\n",
    "m = svm_train(prob,param)\n",
    "\n",
    "print(\"train\")\n",
    "p_lable,p_acc,p_val=svm_predict(train_y, train_x,m)\n",
    "print()\n",
    "print(\"test\")\n",
    "p_lable,p_acc,p_val=svm_predict(test_y, test_x,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel(without setting parameter):\n",
      "train\n",
      "Accuracy = 96.88% (4844/5000) (classification)\n",
      "\n",
      "test\n",
      "Accuracy = 95.32% (2383/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "prob = svm_problem(train_y,train_x)\n",
    "print(\"RBF Kernel(without setting parameter):\")\n",
    "param = svm_parameter('-s 0 -t 2 -q')\n",
    "m = svm_train(prob,param)\n",
    "\n",
    "print(\"train\")\n",
    "p_lable,p_acc,p_val=svm_predict(train_y, train_x,m)\n",
    "print()\n",
    "print(\"test\")\n",
    "p_lable,p_acc,p_val=svm_predict(test_y, test_x,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch C (penalty) for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch_linear(train_y,train_x):\n",
    "    print (\"RUNNING gridSearch for SVC Linear Kernel\")\n",
    "    prob  = svm_problem(train_y, train_x)\n",
    "    bestc=-1\n",
    "    bestCrossVal=-1\n",
    "    grid=[]\n",
    "    for parm in range (-8,1,1):\n",
    "        print(2**parm)\n",
    "        param = svm_parameter(\"-s 0 -q -t 0 -v 3 -c \" + str(2**parm))\n",
    "        m = svm_train(prob,param)\n",
    "        grid.append([2**parm,m])\n",
    "        if (m > bestCrossVal):\n",
    "            bestCrossVal=m\n",
    "            bestc=2**parm \n",
    "    print()\n",
    "    print()\n",
    "    print(\"Parameter C  Vs Accuracy:\")\n",
    "    for C in grid:\n",
    "        print(C)\n",
    "    \n",
    "    return bestc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING gridSearch for SVC Linear Kernel\n",
      "0.00390625\n",
      "Cross Validation Accuracy = 96.3%\n",
      "0.0078125\n",
      "Cross Validation Accuracy = 96.82%\n",
      "0.015625\n",
      "Cross Validation Accuracy = 96.9%\n",
      "0.03125\n",
      "Cross Validation Accuracy = 97.1%\n",
      "0.0625\n",
      "Cross Validation Accuracy = 97.08%\n",
      "0.125\n",
      "Cross Validation Accuracy = 96.76%\n",
      "0.25\n",
      "Cross Validation Accuracy = 96.32%\n",
      "0.5\n",
      "Cross Validation Accuracy = 96.06%\n",
      "1\n",
      "Cross Validation Accuracy = 96.24%\n",
      "\n",
      "\n",
      "Parameter C  Vs Accuracy:\n",
      "[0.00390625, 96.3]\n",
      "[0.0078125, 96.82]\n",
      "[0.015625, 96.89999999999999]\n",
      "[0.03125, 97.1]\n",
      "[0.0625, 97.08]\n",
      "[0.125, 96.76]\n",
      "[0.25, 96.32]\n",
      "[0.5, 96.06]\n",
      "[1, 96.24000000000001]\n"
     ]
    }
   ],
   "source": [
    "bestc = gridSearch_linear(train_y,train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on training data:\n",
      "Accuracy = 98.56% (4928/5000) (classification)\n",
      "Prediction on test data:\n",
      "Accuracy = 96% (2400/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# run on the best c\n",
    "prob  = svm_problem(train_y, train_x)\n",
    "param = svm_parameter(\"-s 0 -q -t 0 -c \" + str(bestc) )\n",
    "m = svm_train(prob, param)\n",
    "print(\"Prediction on training data:\")\n",
    "p_label, p_acc, p_val = svm_predict(train_y, train_x, m)\n",
    "print(\"Prediction on test data:\")\n",
    "p_label, p_acc, p_val = svm_predict(test_y, test_x, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch C (penalty), g (gamma), d (degree) for Polynomial kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch_linear(train_y,train_x):\n",
    "    print (\"RUNNING gridSearch for SVC Polynomial Kernel\")\n",
    "    prob  = svm_problem(train_y, train_x)\n",
    "    bestc=-1\n",
    "    bestg=-1\n",
    "    bestd=-1\n",
    "    bestCrossVal=-1\n",
    "    grid=[]\n",
    "    for d in range (1,5,1) :\n",
    "        for g in range (-2,2,1):\n",
    "            for c in range (-8,1,1):\n",
    "                print('c:',2**c,'g:',2**g,'d:',d)\n",
    "                param = svm_parameter(\"-q -t 1 -v 3 -c \" + str(2**c) +\" -g \" + str (2**g) + \" -d \" + str (d) )\n",
    "                m = svm_train(prob,param)\n",
    "                grid.append([2**c,2**g,d,m])\n",
    "                if (m > bestCrossVal):\n",
    "                    bestCrossVal=m\n",
    "                    bestc=2**c\n",
    "                    bestg=2**g\n",
    "                    bestd=d               \n",
    "    print()\n",
    "    print()\n",
    "    print(\"Parameters c, g, d  Vs Accuracy:\")\n",
    "    for C in grid:\n",
    "        print(C)\n",
    "    \n",
    "    return bestc,bestg,bestd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING gridSearch for SVC Polynomial Kernel\n",
      "c: 0.00390625 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 95.38%\n",
      "c: 0.0078125 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 95.96%\n",
      "c: 0.015625 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 96.32%\n",
      "c: 0.03125 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 96.6%\n",
      "c: 0.0625 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 97%\n",
      "c: 0.125 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 96.8%\n",
      "c: 0.25 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 96.6%\n",
      "c: 0.5 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 96.46%\n",
      "c: 1 g: 0.25 d: 1\n",
      "Cross Validation Accuracy = 96.64%\n",
      "c: 0.00390625 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 95.94%\n",
      "c: 0.0078125 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.36%\n",
      "c: 0.015625 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.78%\n",
      "c: 0.03125 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.98%\n",
      "c: 0.0625 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.9%\n",
      "c: 0.125 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.82%\n",
      "c: 0.25 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.7%\n",
      "c: 0.5 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.36%\n",
      "c: 1 g: 0.5 d: 1\n",
      "Cross Validation Accuracy = 96.04%\n",
      "c: 0.00390625 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.44%\n",
      "c: 0.0078125 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.84%\n",
      "c: 0.015625 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.9%\n",
      "c: 0.03125 g: 1 d: 1\n",
      "Cross Validation Accuracy = 97.1%\n",
      "c: 0.0625 g: 1 d: 1\n",
      "Cross Validation Accuracy = 97.04%\n",
      "c: 0.125 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.66%\n",
      "c: 0.25 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.3%\n",
      "c: 0.5 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.26%\n",
      "c: 1 g: 1 d: 1\n",
      "Cross Validation Accuracy = 96.42%\n",
      "c: 0.00390625 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.52%\n",
      "c: 0.0078125 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.8%\n",
      "c: 0.015625 g: 2 d: 1\n",
      "Cross Validation Accuracy = 97.18%\n",
      "c: 0.03125 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.74%\n",
      "c: 0.0625 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.68%\n",
      "c: 0.125 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.42%\n",
      "c: 0.25 g: 2 d: 1\n",
      "Cross Validation Accuracy = 95.86%\n",
      "c: 0.5 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.06%\n",
      "c: 1 g: 2 d: 1\n",
      "Cross Validation Accuracy = 96.16%\n",
      "c: 0.00390625 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.74%\n",
      "c: 0.0078125 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.8%\n",
      "c: 0.015625 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.92%\n",
      "c: 0.03125 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.82%\n",
      "c: 0.0625 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.62%\n",
      "c: 0.125 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.92%\n",
      "c: 0.25 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.94%\n",
      "c: 0.5 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.84%\n",
      "c: 1 g: 0.25 d: 2\n",
      "Cross Validation Accuracy = 97.72%\n",
      "c: 0.00390625 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.96%\n",
      "c: 0.0078125 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.88%\n",
      "c: 0.015625 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.88%\n",
      "c: 0.03125 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.94%\n",
      "c: 0.0625 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.96%\n",
      "c: 0.125 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.9%\n",
      "c: 0.25 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.88%\n",
      "c: 0.5 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 98.02%\n",
      "c: 1 g: 0.5 d: 2\n",
      "Cross Validation Accuracy = 97.9%\n",
      "c: 0.00390625 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.84%\n",
      "c: 0.0078125 g: 1 d: 2\n",
      "Cross Validation Accuracy = 98.08%\n",
      "c: 0.015625 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.88%\n",
      "c: 0.03125 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.78%\n",
      "c: 0.0625 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.62%\n",
      "c: 0.125 g: 1 d: 2\n",
      "Cross Validation Accuracy = 98%\n",
      "c: 0.25 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.98%\n",
      "c: 0.5 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.8%\n",
      "c: 1 g: 1 d: 2\n",
      "Cross Validation Accuracy = 97.94%\n",
      "c: 0.00390625 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.92%\n",
      "c: 0.0078125 g: 2 d: 2\n",
      "Cross Validation Accuracy = 98.02%\n",
      "c: 0.015625 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.96%\n",
      "c: 0.03125 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.76%\n",
      "c: 0.0625 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.94%\n",
      "c: 0.125 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.9%\n",
      "c: 0.25 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.98%\n",
      "c: 0.5 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.9%\n",
      "c: 1 g: 2 d: 2\n",
      "Cross Validation Accuracy = 97.94%\n",
      "c: 0.00390625 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.64%\n",
      "c: 0.0078125 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.28%\n",
      "c: 0.015625 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.32%\n",
      "c: 0.03125 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.46%\n",
      "c: 0.0625 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.7%\n",
      "c: 0.125 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.32%\n",
      "c: 0.25 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.44%\n",
      "c: 0.5 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.28%\n",
      "c: 1 g: 0.25 d: 3\n",
      "Cross Validation Accuracy = 97.5%\n",
      "c: 0.00390625 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.44%\n",
      "c: 0.0078125 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.52%\n",
      "c: 0.015625 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.36%\n",
      "c: 0.03125 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.4%\n",
      "c: 0.0625 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.64%\n",
      "c: 0.125 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.3%\n",
      "c: 0.25 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.36%\n",
      "c: 0.5 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.32%\n",
      "c: 1 g: 0.5 d: 3\n",
      "Cross Validation Accuracy = 97.36%\n",
      "c: 0.00390625 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.42%\n",
      "c: 0.0078125 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.34%\n",
      "c: 0.015625 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.4%\n",
      "c: 0.03125 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.28%\n",
      "c: 0.0625 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.48%\n",
      "c: 0.125 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.3%\n",
      "c: 0.25 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.7%\n",
      "c: 0.5 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.3%\n",
      "c: 1 g: 1 d: 3\n",
      "Cross Validation Accuracy = 97.6%\n",
      "c: 0.00390625 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.28%\n",
      "c: 0.0078125 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.56%\n",
      "c: 0.015625 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.52%\n",
      "c: 0.03125 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.4%\n",
      "c: 0.0625 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.8%\n",
      "c: 0.125 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.7%\n",
      "c: 0.25 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.34%\n",
      "c: 0.5 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.34%\n",
      "c: 1 g: 2 d: 3\n",
      "Cross Validation Accuracy = 97.48%\n",
      "c: 0.00390625 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.3%\n",
      "c: 0.0078125 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.26%\n",
      "c: 0.015625 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.18%\n",
      "c: 0.03125 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.36%\n",
      "c: 0.0625 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.16%\n",
      "c: 0.125 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.2%\n",
      "c: 0.25 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.12%\n",
      "c: 0.5 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.34%\n",
      "c: 1 g: 0.25 d: 4\n",
      "Cross Validation Accuracy = 96.36%\n",
      "c: 0.00390625 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 95.84%\n",
      "c: 0.0078125 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.4%\n",
      "c: 0.015625 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.36%\n",
      "c: 0.03125 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.06%\n",
      "c: 0.0625 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.4%\n",
      "c: 0.125 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.26%\n",
      "c: 0.25 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.26%\n",
      "c: 0.5 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.08%\n",
      "c: 1 g: 0.5 d: 4\n",
      "Cross Validation Accuracy = 96.18%\n",
      "c: 0.00390625 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.18%\n",
      "c: 0.0078125 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.26%\n",
      "c: 0.015625 g: 1 d: 4\n",
      "Cross Validation Accuracy = 95.98%\n",
      "c: 0.03125 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.08%\n",
      "c: 0.0625 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.3%\n",
      "c: 0.125 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.16%\n",
      "c: 0.25 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.4%\n",
      "c: 0.5 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.14%\n",
      "c: 1 g: 1 d: 4\n",
      "Cross Validation Accuracy = 96.32%\n",
      "c: 0.00390625 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.36%\n",
      "c: 0.0078125 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.08%\n",
      "c: 0.015625 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.08%\n",
      "c: 0.03125 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.28%\n",
      "c: 0.0625 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.08%\n",
      "c: 0.125 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.32%\n",
      "c: 0.25 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.46%\n",
      "c: 0.5 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.16%\n",
      "c: 1 g: 2 d: 4\n",
      "Cross Validation Accuracy = 96.22%\n",
      "\n",
      "\n",
      "Parameters c, g, d  Vs Accuracy:\n",
      "[0.00390625, 0.25, 1, 95.38]\n",
      "[0.0078125, 0.25, 1, 95.96000000000001]\n",
      "[0.015625, 0.25, 1, 96.32]\n",
      "[0.03125, 0.25, 1, 96.6]\n",
      "[0.0625, 0.25, 1, 97.0]\n",
      "[0.125, 0.25, 1, 96.8]\n",
      "[0.25, 0.25, 1, 96.6]\n",
      "[0.5, 0.25, 1, 96.46000000000001]\n",
      "[1, 0.25, 1, 96.64]\n",
      "[0.00390625, 0.5, 1, 95.94]\n",
      "[0.0078125, 0.5, 1, 96.36]\n",
      "[0.015625, 0.5, 1, 96.78]\n",
      "[0.03125, 0.5, 1, 96.98]\n",
      "[0.0625, 0.5, 1, 96.89999999999999]\n",
      "[0.125, 0.5, 1, 96.82]\n",
      "[0.25, 0.5, 1, 96.7]\n",
      "[0.5, 0.5, 1, 96.36]\n",
      "[1, 0.5, 1, 96.04]\n",
      "[0.00390625, 1, 1, 96.44]\n",
      "[0.0078125, 1, 1, 96.84]\n",
      "[0.015625, 1, 1, 96.89999999999999]\n",
      "[0.03125, 1, 1, 97.1]\n",
      "[0.0625, 1, 1, 97.04]\n",
      "[0.125, 1, 1, 96.66]\n",
      "[0.25, 1, 1, 96.3]\n",
      "[0.5, 1, 1, 96.26]\n",
      "[1, 1, 1, 96.41999999999999]\n",
      "[0.00390625, 2, 1, 96.52]\n",
      "[0.0078125, 2, 1, 96.8]\n",
      "[0.015625, 2, 1, 97.18]\n",
      "[0.03125, 2, 1, 96.74000000000001]\n",
      "[0.0625, 2, 1, 96.67999999999999]\n",
      "[0.125, 2, 1, 96.41999999999999]\n",
      "[0.25, 2, 1, 95.86]\n",
      "[0.5, 2, 1, 96.06]\n",
      "[1, 2, 1, 96.16]\n",
      "[0.00390625, 0.25, 2, 97.74000000000001]\n",
      "[0.0078125, 0.25, 2, 97.8]\n",
      "[0.015625, 0.25, 2, 97.92]\n",
      "[0.03125, 0.25, 2, 97.82]\n",
      "[0.0625, 0.25, 2, 97.61999999999999]\n",
      "[0.125, 0.25, 2, 97.92]\n",
      "[0.25, 0.25, 2, 97.94]\n",
      "[0.5, 0.25, 2, 97.84]\n",
      "[1, 0.25, 2, 97.72]\n",
      "[0.00390625, 0.5, 2, 97.96000000000001]\n",
      "[0.0078125, 0.5, 2, 97.88]\n",
      "[0.015625, 0.5, 2, 97.88]\n",
      "[0.03125, 0.5, 2, 97.94]\n",
      "[0.0625, 0.5, 2, 97.96000000000001]\n",
      "[0.125, 0.5, 2, 97.89999999999999]\n",
      "[0.25, 0.5, 2, 97.88]\n",
      "[0.5, 0.5, 2, 98.02]\n",
      "[1, 0.5, 2, 97.89999999999999]\n",
      "[0.00390625, 1, 2, 97.84]\n",
      "[0.0078125, 1, 2, 98.08]\n",
      "[0.015625, 1, 2, 97.88]\n",
      "[0.03125, 1, 2, 97.78]\n",
      "[0.0625, 1, 2, 97.61999999999999]\n",
      "[0.125, 1, 2, 98.0]\n",
      "[0.25, 1, 2, 97.98]\n",
      "[0.5, 1, 2, 97.8]\n",
      "[1, 1, 2, 97.94]\n",
      "[0.00390625, 2, 2, 97.92]\n",
      "[0.0078125, 2, 2, 98.02]\n",
      "[0.015625, 2, 2, 97.96000000000001]\n",
      "[0.03125, 2, 2, 97.76]\n",
      "[0.0625, 2, 2, 97.94]\n",
      "[0.125, 2, 2, 97.89999999999999]\n",
      "[0.25, 2, 2, 97.98]\n",
      "[0.5, 2, 2, 97.89999999999999]\n",
      "[1, 2, 2, 97.94]\n",
      "[0.00390625, 0.25, 3, 97.64]\n",
      "[0.0078125, 0.25, 3, 97.28]\n",
      "[0.015625, 0.25, 3, 97.32]\n",
      "[0.03125, 0.25, 3, 97.46000000000001]\n",
      "[0.0625, 0.25, 3, 97.7]\n",
      "[0.125, 0.25, 3, 97.32]\n",
      "[0.25, 0.25, 3, 97.44]\n",
      "[0.5, 0.25, 3, 97.28]\n",
      "[1, 0.25, 3, 97.5]\n",
      "[0.00390625, 0.5, 3, 97.44]\n",
      "[0.0078125, 0.5, 3, 97.52]\n",
      "[0.015625, 0.5, 3, 97.36]\n",
      "[0.03125, 0.5, 3, 97.39999999999999]\n",
      "[0.0625, 0.5, 3, 97.64]\n",
      "[0.125, 0.5, 3, 97.3]\n",
      "[0.25, 0.5, 3, 97.36]\n",
      "[0.5, 0.5, 3, 97.32]\n",
      "[1, 0.5, 3, 97.36]\n",
      "[0.00390625, 1, 3, 97.42]\n",
      "[0.0078125, 1, 3, 97.34]\n",
      "[0.015625, 1, 3, 97.39999999999999]\n",
      "[0.03125, 1, 3, 97.28]\n",
      "[0.0625, 1, 3, 97.48]\n",
      "[0.125, 1, 3, 97.3]\n",
      "[0.25, 1, 3, 97.7]\n",
      "[0.5, 1, 3, 97.3]\n",
      "[1, 1, 3, 97.6]\n",
      "[0.00390625, 2, 3, 97.28]\n",
      "[0.0078125, 2, 3, 97.56]\n",
      "[0.015625, 2, 3, 97.52]\n",
      "[0.03125, 2, 3, 97.39999999999999]\n",
      "[0.0625, 2, 3, 97.8]\n",
      "[0.125, 2, 3, 97.7]\n",
      "[0.25, 2, 3, 97.34]\n",
      "[0.5, 2, 3, 97.34]\n",
      "[1, 2, 3, 97.48]\n",
      "[0.00390625, 0.25, 4, 96.3]\n",
      "[0.0078125, 0.25, 4, 96.26]\n",
      "[0.015625, 0.25, 4, 96.17999999999999]\n",
      "[0.03125, 0.25, 4, 96.36]\n",
      "[0.0625, 0.25, 4, 96.16]\n",
      "[0.125, 0.25, 4, 96.2]\n",
      "[0.25, 0.25, 4, 96.12]\n",
      "[0.5, 0.25, 4, 96.34]\n",
      "[1, 0.25, 4, 96.36]\n",
      "[0.00390625, 0.5, 4, 95.84]\n",
      "[0.0078125, 0.5, 4, 96.39999999999999]\n",
      "[0.015625, 0.5, 4, 96.36]\n",
      "[0.03125, 0.5, 4, 96.06]\n",
      "[0.0625, 0.5, 4, 96.39999999999999]\n",
      "[0.125, 0.5, 4, 96.26]\n",
      "[0.25, 0.5, 4, 96.26]\n",
      "[0.5, 0.5, 4, 96.08]\n",
      "[1, 0.5, 4, 96.17999999999999]\n",
      "[0.00390625, 1, 4, 96.17999999999999]\n",
      "[0.0078125, 1, 4, 96.26]\n",
      "[0.015625, 1, 4, 95.98]\n",
      "[0.03125, 1, 4, 96.08]\n",
      "[0.0625, 1, 4, 96.3]\n",
      "[0.125, 1, 4, 96.16]\n",
      "[0.25, 1, 4, 96.39999999999999]\n",
      "[0.5, 1, 4, 96.14]\n",
      "[1, 1, 4, 96.32]\n",
      "[0.00390625, 2, 4, 96.36]\n",
      "[0.0078125, 2, 4, 96.08]\n",
      "[0.015625, 2, 4, 96.08]\n",
      "[0.03125, 2, 4, 96.28]\n",
      "[0.0625, 2, 4, 96.08]\n",
      "[0.125, 2, 4, 96.32]\n",
      "[0.25, 2, 4, 96.46000000000001]\n",
      "[0.5, 2, 4, 96.16]\n",
      "[1, 2, 4, 96.22]\n"
     ]
    }
   ],
   "source": [
    "bestc,bestg,bestd = gridSearch_linear(train_y,train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on training data:\n",
      "Accuracy = 100% (5000/5000) (classification)\n",
      "Prediction on test data:\n",
      "Accuracy = 97.68% (2442/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# run on the best c\n",
    "prob  = svm_problem(train_y, train_x)\n",
    "param = svm_parameter(\"-s 0 -q -t 1 -c \" + str(bestc)  +\" -g \" + str (bestg) + \" -d \" + str (bestd) )\n",
    "m = svm_train(prob, param)\n",
    "print(\"Prediction on training data:\")\n",
    "p_label, p_acc, p_val = svm_predict(train_y, train_x, m)\n",
    "print(\"Prediction on test data:\")\n",
    "p_label, p_acc, p_val = svm_predict(test_y, test_x, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch C (penalty), g (gamma), for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch_linear(train_y,train_x):\n",
    "    print (\"RUNNING gridSearch for SVC RBF Kernel\")\n",
    "    prob  = svm_problem(train_y, train_x)\n",
    "    bestc=-1\n",
    "    bestg=-1\n",
    "    bestCrossVal=-1\n",
    "    grid=[]\n",
    "    for g in range (-4,2,1):\n",
    "        for c in range (-8,1,1):\n",
    "            print('c:',2**c,'g:',2**g)\n",
    "            param = svm_parameter(\"-q -t 2 -v 3 -c \" + str(2**c) +\" -g \" + str (2**g) ) \n",
    "            m = svm_train(prob,param)\n",
    "            grid.append([2**c,2**g,m])\n",
    "            if (m > bestCrossVal):\n",
    "                bestCrossVal=m\n",
    "                bestc=2**c\n",
    "                bestg=2**g\n",
    "                                                   \n",
    "    print()\n",
    "    print()\n",
    "    print(\"Parameters c, g, Vs Accuracy:\")\n",
    "    for C in grid:\n",
    "        print(C)\n",
    "    \n",
    "    return bestc,bestg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING gridSearch for SVC RBF Kernel\n",
      "c: 0.00390625 g: 0.0625\n",
      "Cross Validation Accuracy = 71.5%\n",
      "c: 0.0078125 g: 0.0625\n",
      "Cross Validation Accuracy = 71.26%\n",
      "c: 0.015625 g: 0.0625\n",
      "Cross Validation Accuracy = 71.44%\n",
      "c: 0.03125 g: 0.0625\n",
      "Cross Validation Accuracy = 73.5%\n",
      "c: 0.0625 g: 0.0625\n",
      "Cross Validation Accuracy = 74.72%\n",
      "c: 0.125 g: 0.0625\n",
      "Cross Validation Accuracy = 84.58%\n",
      "c: 0.25 g: 0.0625\n",
      "Cross Validation Accuracy = 93%\n",
      "c: 0.5 g: 0.0625\n",
      "Cross Validation Accuracy = 96.76%\n",
      "c: 1 g: 0.0625\n",
      "Cross Validation Accuracy = 97.84%\n",
      "c: 0.00390625 g: 0.125\n",
      "Cross Validation Accuracy = 42.44%\n",
      "c: 0.0078125 g: 0.125\n",
      "Cross Validation Accuracy = 43.04%\n",
      "c: 0.015625 g: 0.125\n",
      "Cross Validation Accuracy = 41.8%\n",
      "c: 0.03125 g: 0.125\n",
      "Cross Validation Accuracy = 42.02%\n",
      "c: 0.0625 g: 0.125\n",
      "Cross Validation Accuracy = 45.64%\n",
      "c: 0.125 g: 0.125\n",
      "Cross Validation Accuracy = 47.48%\n",
      "c: 0.25 g: 0.125\n",
      "Cross Validation Accuracy = 49.16%\n",
      "c: 0.5 g: 0.125\n",
      "Cross Validation Accuracy = 55.04%\n",
      "c: 1 g: 0.125\n",
      "Cross Validation Accuracy = 83.88%\n",
      "c: 0.00390625 g: 0.25\n",
      "Cross Validation Accuracy = 27.56%\n",
      "c: 0.0078125 g: 0.25\n",
      "Cross Validation Accuracy = 26.6%\n",
      "c: 0.015625 g: 0.25\n",
      "Cross Validation Accuracy = 26.9%\n",
      "c: 0.03125 g: 0.25\n",
      "Cross Validation Accuracy = 26.54%\n",
      "c: 0.0625 g: 0.25\n",
      "Cross Validation Accuracy = 29.34%\n",
      "c: 0.125 g: 0.25\n",
      "Cross Validation Accuracy = 29.72%\n",
      "c: 0.25 g: 0.25\n",
      "Cross Validation Accuracy = 34.76%\n",
      "c: 0.5 g: 0.25\n",
      "Cross Validation Accuracy = 38.6%\n",
      "c: 1 g: 0.25\n",
      "Cross Validation Accuracy = 62.2%\n",
      "c: 0.00390625 g: 0.5\n",
      "Cross Validation Accuracy = 21.48%\n",
      "c: 0.0078125 g: 0.5\n",
      "Cross Validation Accuracy = 21.86%\n",
      "c: 0.015625 g: 0.5\n",
      "Cross Validation Accuracy = 21.7%\n",
      "c: 0.03125 g: 0.5\n",
      "Cross Validation Accuracy = 21.64%\n",
      "c: 0.0625 g: 0.5\n",
      "Cross Validation Accuracy = 21.88%\n",
      "c: 0.125 g: 0.5\n",
      "Cross Validation Accuracy = 21.64%\n",
      "c: 0.25 g: 0.5\n",
      "Cross Validation Accuracy = 21.96%\n",
      "c: 0.5 g: 0.5\n",
      "Cross Validation Accuracy = 25.44%\n",
      "c: 1 g: 0.5\n",
      "Cross Validation Accuracy = 44.78%\n",
      "c: 0.00390625 g: 1\n",
      "Cross Validation Accuracy = 20.62%\n",
      "c: 0.0078125 g: 1\n",
      "Cross Validation Accuracy = 20.88%\n",
      "c: 0.015625 g: 1\n",
      "Cross Validation Accuracy = 20.56%\n",
      "c: 0.03125 g: 1\n",
      "Cross Validation Accuracy = 20.5%\n",
      "c: 0.0625 g: 1\n",
      "Cross Validation Accuracy = 20.4%\n",
      "c: 0.125 g: 1\n",
      "Cross Validation Accuracy = 20.62%\n",
      "c: 0.25 g: 1\n",
      "Cross Validation Accuracy = 20.6%\n",
      "c: 0.5 g: 1\n",
      "Cross Validation Accuracy = 20.98%\n",
      "c: 1 g: 1\n",
      "Cross Validation Accuracy = 29.46%\n",
      "c: 0.00390625 g: 2\n",
      "Cross Validation Accuracy = 20.28%\n",
      "c: 0.0078125 g: 2\n",
      "Cross Validation Accuracy = 20.36%\n",
      "c: 0.015625 g: 2\n",
      "Cross Validation Accuracy = 20.4%\n",
      "c: 0.03125 g: 2\n",
      "Cross Validation Accuracy = 20.3%\n",
      "c: 0.0625 g: 2\n",
      "Cross Validation Accuracy = 20.34%\n",
      "c: 0.125 g: 2\n",
      "Cross Validation Accuracy = 20.3%\n",
      "c: 0.25 g: 2\n",
      "Cross Validation Accuracy = 20.44%\n",
      "c: 0.5 g: 2\n",
      "Cross Validation Accuracy = 20.24%\n",
      "c: 1 g: 2\n",
      "Cross Validation Accuracy = 24.02%\n",
      "\n",
      "\n",
      "Parameters c, g, Vs Accuracy:\n",
      "[0.00390625, 0.0625, 71.5]\n",
      "[0.0078125, 0.0625, 71.26]\n",
      "[0.015625, 0.0625, 71.44]\n",
      "[0.03125, 0.0625, 73.5]\n",
      "[0.0625, 0.0625, 74.72]\n",
      "[0.125, 0.0625, 84.58]\n",
      "[0.25, 0.0625, 93.0]\n",
      "[0.5, 0.0625, 96.76]\n",
      "[1, 0.0625, 97.84]\n",
      "[0.00390625, 0.125, 42.44]\n",
      "[0.0078125, 0.125, 43.04]\n",
      "[0.015625, 0.125, 41.8]\n",
      "[0.03125, 0.125, 42.02]\n",
      "[0.0625, 0.125, 45.64]\n",
      "[0.125, 0.125, 47.48]\n",
      "[0.25, 0.125, 49.16]\n",
      "[0.5, 0.125, 55.04]\n",
      "[1, 0.125, 83.88]\n",
      "[0.00390625, 0.25, 27.560000000000002]\n",
      "[0.0078125, 0.25, 26.6]\n",
      "[0.015625, 0.25, 26.900000000000002]\n",
      "[0.03125, 0.25, 26.540000000000003]\n",
      "[0.0625, 0.25, 29.34]\n",
      "[0.125, 0.25, 29.720000000000002]\n",
      "[0.25, 0.25, 34.760000000000005]\n",
      "[0.5, 0.25, 38.6]\n",
      "[1, 0.25, 62.2]\n",
      "[0.00390625, 0.5, 21.48]\n",
      "[0.0078125, 0.5, 21.86]\n",
      "[0.015625, 0.5, 21.7]\n",
      "[0.03125, 0.5, 21.64]\n",
      "[0.0625, 0.5, 21.88]\n",
      "[0.125, 0.5, 21.64]\n",
      "[0.25, 0.5, 21.959999999999997]\n",
      "[0.5, 0.5, 25.44]\n",
      "[1, 0.5, 44.78]\n",
      "[0.00390625, 1, 20.62]\n",
      "[0.0078125, 1, 20.880000000000003]\n",
      "[0.015625, 1, 20.560000000000002]\n",
      "[0.03125, 1, 20.5]\n",
      "[0.0625, 1, 20.4]\n",
      "[0.125, 1, 20.62]\n",
      "[0.25, 1, 20.599999999999998]\n",
      "[0.5, 1, 20.979999999999997]\n",
      "[1, 1, 29.459999999999997]\n",
      "[0.00390625, 2, 20.28]\n",
      "[0.0078125, 2, 20.36]\n",
      "[0.015625, 2, 20.4]\n",
      "[0.03125, 2, 20.3]\n",
      "[0.0625, 2, 20.34]\n",
      "[0.125, 2, 20.3]\n",
      "[0.25, 2, 20.44]\n",
      "[0.5, 2, 20.24]\n",
      "[1, 2, 24.02]\n"
     ]
    }
   ],
   "source": [
    "bestc,bestg= gridSearch_linear(train_y,train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on training data:\n",
      "Accuracy = 100% (5000/5000) (classification)\n",
      "Prediction on test data:\n",
      "Accuracy = 97.36% (2434/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# run on the best c\n",
    "prob  = svm_problem(train_y, train_x)\n",
    "param = svm_parameter(\"-s 0 -q -t 2 -c \" + str(bestc)  +\" -g \" + str (bestg) )\n",
    "m = svm_train(prob, param)\n",
    "print(\"Prediction on training data:\")\n",
    "p_label, p_acc, p_val = svm_predict(train_y, train_x, m)\n",
    "print(\"Prediction on test data:\")\n",
    "p_label, p_acc, p_val = svm_predict(test_y, test_x, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined Linear+RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_defined_kernel(train_y,train_x,test_y,test_x):\n",
    "    \n",
    "    #define linear kernal using linear kernel formula K(x,x')=x.T.dot(x')\n",
    "    g = 0.125\n",
    "    print(\"Computing Linear Kernel\")\n",
    "    LK_Train = train_x.dot(train_x.T)\n",
    "    idx1 = range(1,len(train_x)+1)\n",
    "    LK_Train = np.column_stack([idx1, LK_Train])\n",
    "    LK_Train = (LK_Train).tolist()\n",
    "\n",
    "    LK_Test = test_x.dot(train_x.T)\n",
    "    idx2 = range (1,len(test_x)+1)\n",
    "    LK_Test = np.column_stack([idx2, LK_Test])\n",
    "    LK_Test = (LK_Test).tolist()\n",
    "    \n",
    "    #define RBF kernel using RBF kernel formula e^gamma||xi-xj||\n",
    "    print(\"Computing RBF Kernel\")\n",
    "    dist= np.zeros((len(train_x),len(train_x)))\n",
    "\n",
    "    for i in range (len(train_x)):\n",
    "        for j in range (i,len(train_x),1):\n",
    "            dist[i,j] = np.linalg.norm(train_x[i]-train_x[j])\n",
    "            dist[j,i] = dist[i,j]\n",
    "\n",
    "    RBK_Train = np.zeros((len(train_x),len(train_x)))\n",
    "\n",
    "    for i in range (len(train_x)):\n",
    "        for j in range (i,len(train_x),1):\n",
    "            RBK_Train[i,j] =  exp((-g)*dist[i,j])\n",
    "            RBK_Train[j,i] =  RBK_Train[i,j]\n",
    "\n",
    "\n",
    "    idx3 = range(1,len(train_x)+1)\n",
    "    RBK_Train = np.column_stack([idx3, RBK_Train])\n",
    "    RBK_Train = (RBK_Train).tolist()\n",
    "\n",
    "    distTest= np.zeros((len(train_x),len(train_x)))\n",
    "\n",
    "    for i in range (len(test_x)):\n",
    "        for j in range (len(train_x)):\n",
    "            distTest[i,j] = np.linalg.norm(test_x[i]-train_x[j])\n",
    "\n",
    "    RBK_Test = np.zeros((len(test_x),len(train_x)))\n",
    "\n",
    "    for i in range (len(test_x)):\n",
    "        for j in range (len(train_x)):\n",
    "            RBK_Test[i,j] = exp((-g) *distTest[i,j])\n",
    "\n",
    "    idx4 = range (1,len(test_x)+1)\n",
    "    RBK_Test = np.column_stack([idx4, RBK_Test])\n",
    "    RBK_Test = (RBK_Test).tolist()\n",
    "   \n",
    "    #combine Linear and RBF Kerel; Linear+RBF Kernel\n",
    "    print(\"Computing Linear+RBF Kernel\")\n",
    "    RBL_Train = np.zeros((len(train_x),len(train_x)))\n",
    "\n",
    "    for i in range (len(train_x)):\n",
    "        for j in range (i,len(train_x),1):\n",
    "            RBL_Train[i,j] = LK_Train[i][j+1] + RBK_Train[i][j+1]\n",
    "            RBL_Train[j,i] =  RBL_Train[i,j]\n",
    "    idx5 = range (1,len(train_x)+1)\n",
    "    RBL_Train = np.column_stack([idx5, RBL_Train])\n",
    "    RBL_Train = (RBL_Train).tolist()\n",
    "\n",
    "    RBL_Test = np.zeros((len(test_x),len(train_x)))\n",
    "    for i in range (len(test_x)):\n",
    "        for j in range (1,len(train_x),1):\n",
    "            RBL_Test[i,j] = LK_Test[i][j+1] + RBK_Test[i][j+1]       \n",
    "    idx6 = range(1,len(test_x)+1)\n",
    "    RBL_Test = np.column_stack([idx6, RBL_Test])\n",
    "    RBL_Test = (RBL_Test).tolist()\n",
    "    \n",
    "    print(\"Training and testing uisng User Defined LINEAR + RBF \")\n",
    "    prob  = svm_problem(train_y, RBL_Train, isKernel=True)\n",
    "    param = svm_parameter('-t 4 -c 0.0156 -q') \n",
    "    m = svm_train(prob, param)\n",
    "    p_label, p_acc, p_val = svm_predict(test_y, RBL_Test, m)\n",
    "    sv_idx_linear_rbf = m.get_sv_indices()\n",
    "    \n",
    "    return p_label, sv_idx_linear_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Linear Kernel\n",
      "Computing RBF Kernel\n",
      "Computing Linear+RBF Kernel\n",
      "Training and testing uisng User Defined LINEAR + RBF \n",
      "Accuracy = 95.96% (2399/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "_=user_defined_kernel(train_y,train_x,test_y,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
