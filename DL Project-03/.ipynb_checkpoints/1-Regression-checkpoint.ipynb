{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"energy_efficiency_data.csv\")\n",
    "\n",
    "ort = pd.get_dummies(X['Orientation'], prefix='Orientation', drop_first=False)\n",
    "X = pd.concat([X,ort], axis=1)\n",
    "gad = pd.get_dummies(X['Glazing Area Distribution'], prefix='Glazing Area Distribution', drop_first=True)\n",
    "\n",
    "X = pd.concat([X, gad], axis=1)\n",
    "drop_features = ['Orientation', 'Glazing Area Distribution','Cooling Load',]\n",
    "X = X.drop(drop_features, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_mat =X.corr()\n",
    "cor_mat.style.background_gradient().set_precision(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = ['Heating Load']\n",
    "X, Y = X.drop(Y, axis=1), X[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train =np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neural_network():\n",
    "    def __init__(self,structure,input_dimention,lamda=0.001):\n",
    "        self.structure = structure\n",
    "        self.weight = []\n",
    "        self.erms = []\n",
    "        self.final = []\n",
    "\n",
    "        for i in range(0,len(structure)):\n",
    "            if i==0:\n",
    "                self.weight.append(np.random.rand(structure[i],input_dimention+1)*lamda)\n",
    "            else:\n",
    "                self.weight.append(np.random.rand(structure[i],structure[i-1]+1)*lamda)\n",
    "                \n",
    "    def train(self,features,target,epoch,learning_rate,batch_size,lamb):\n",
    "        for iter in range(0,epoch):\n",
    "            output = []\n",
    "            num = np.arange(len(features))\n",
    "            batch_data = 0\n",
    "            temp_dweight = []\n",
    "            for index in range(0,len(features)):\n",
    "                X = np.c_[np.mat(features[num[index]]),1]\n",
    "                Activation = []\n",
    "                d_weight = []\n",
    "               \n",
    "                for layer in range(0,len(self.structure)):\n",
    "                    w = [self.weight[layer][node] for node in range(0,self.structure[layer])]\n",
    "                    Weight = np.mat(w)\n",
    "                    if layer==0:\n",
    "                        temp = []\n",
    "                        for node in range(0,self.structure[layer]):\n",
    "                            x = X * np.transpose(Weight[node])\n",
    "                            temp.append(x[0,0])\n",
    "                        Activation.append(temp)\n",
    "                    else:\n",
    "                             temp = []\n",
    "                             activ = np.mat(Activation[layer-1])\n",
    "                             activ = np.c_[activ,1]\n",
    "                             for node in range(0,self.structure[layer]):\n",
    "                                      x = activ * np.transpose(Weight[node])\n",
    "                                      temp.append(x[0,0])\n",
    "                             Activation.append(temp)\n",
    "                output.append(Activation)\n",
    "                    \t\t\t\t\n",
    "                error = output[index][len(self.structure)-1] - target[num[index]]\n",
    "                d_weight = []\n",
    "                d_activation = []\n",
    "                for layer in range(0,len(self.structure)):\n",
    "                    d_J = []\n",
    "                    dJ_d_activ = []\n",
    "                    _layer = len(self.structure) - 1 - layer\n",
    "                    w = [self.weight[_layer][node] for node in range(0,self.structure[_layer])]\n",
    "                    if layer == 0:\n",
    "                        w = w[0][0:(len(w[0])-1)]\n",
    "                        err = output[index][_layer-1]\n",
    "                        err.append(1)\n",
    "                        d_J.append(error * np.array(err))\n",
    "                        d_weight.append(d_J)\n",
    "                        d_activation.append(error * np.array(w))\n",
    "                    else:\n",
    "                        if layer != (len(self.structure)-1):\n",
    "                            err = output[index][_layer-1]\n",
    "                            err.append(1)\n",
    "                            [d_J.append(d_activation[layer-1][node] * np.array(err)) for node in range(0,self.structure[_layer])]\n",
    "                            d_weight.append(d_J)\n",
    "                            [dJ_d_activ.append(d_activation[layer-1][node] * np.array(w[node][0:(len(w[node])-1)])) for node in range(0,self.structure[_layer])]\n",
    "                            for node in range(0,len(dJ_d_activ)):\n",
    "                                if node!=0:\n",
    "                                    dJ_d_activ[0] = np.array(dJ_d_activ[0]) + np.array(dJ_d_activ[node])\n",
    "                            d_activation.append(dJ_d_activ[0])\n",
    "                        else:\n",
    "                            err = np.append(np.array(features[index]),1)\n",
    "                            [d_J.append(d_activation[layer-1][node] * np.array(err)) for node in range(0,self.structure[_layer])]\n",
    "                            d_weight.append(d_J)\n",
    "                temp_dweight.append(d_weight)\n",
    "                if np.round(iter/batch_size)==iter/batch_size or iter!=0:\n",
    "                    if iter != (epoch-1):\n",
    "                        for layer in range(0,len(self.structure)):\n",
    "                            for node in range(0,self.structure[layer]):\n",
    "                                self.weight[layer][node] = self.weight[layer][node] - (learning_rate * temp_dweight[0][len(self.structure)-1-layer][node])\n",
    "                        batch_data = 0\n",
    "                        temp_dweight = []\n",
    "                else:\n",
    "                    if batch_data!=0:\n",
    "                        for layer in range(0,len(self.structure)):\n",
    "                            for node in range(0,self.structure[layer]):\n",
    "                                temp_dweight[0][layer][node] = temp_dweight[batch_data][layer][node] + temp_dweight[0][layer][node]\n",
    "                    batch_data = batch_data + 1\n",
    "                if iter==(epoch-1):\n",
    "                    self.final.append(output[index][len(self.structure)-1])\n",
    "            output = np.array(output)\n",
    "            SSE = np.sum([(target[id] - output[id,len(self.structure)-1])**2 for id in range(0,len(features))])\n",
    "            #print(iter,np.sqrt(SSE/len(features)))\n",
    "            self.erms.append(np.sqrt(SSE/len(features)))\n",
    "        #print(self.weight[0])\n",
    "#%% \n",
    "    def test(self,features_test,target):\n",
    "        MSE = 0\n",
    "        Erms = []\n",
    "        output = []\n",
    "        final = []\n",
    "        for index in range(0,len(features_test)):\n",
    "            X = np.c_[np.mat(features_test[index]),1]\n",
    "            Activation = []\n",
    "            for layer in range(0,len(self.structure)):\n",
    "                w = [self.weight[layer][node] for node in range(0,self.structure[layer])]\n",
    "                Weight= np.mat(w)\n",
    "                if layer==0:\n",
    "                    temp = []\n",
    "                    for node in range(0,self.structure[layer]):\n",
    "                        x = X * np.transpose(Weight[node])\n",
    "                        temp.append(x[0,0])\n",
    "                    Activation.append(temp)\n",
    "                else:\n",
    "                    temp = []\n",
    "                    activ = np.mat(Activation[layer-1])\n",
    "                    activ = np.c_[activ,1]\n",
    "                    for node in range(0,self.structure[layer]):\n",
    "                        x = activ * np.transpose(Weight[node])\n",
    "                        temp.append(x[0,0])\n",
    "                    Activation.append(temp)\n",
    "            output.append(Activation)\n",
    "            MSE = MSE + ((output[index][len(self.structure)-1] - target[index])**2)\n",
    "            final.append(output[index][len(self.structure)-1])\n",
    "        Erms = np.sqrt(MSE/len(features_test))\n",
    "        return Erms,final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.... \n"
     ]
    }
   ],
   "source": [
    "#epoch,learning_rate,batch_size,lamb        \n",
    "Lr = 0.000001\n",
    "epoch = 1000\n",
    "batch_size=32\n",
    "print(\"Running.... \")\n",
    "NN = neural_network([10,10,1],X_train.shape[1])\n",
    "NN.train(X_train,Y_train,epoch,Lr,batch_size,0)\n",
    "#%%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ERMS 6.57441929181329\n",
      "Test ERMS [5.989695]\n",
      "learning rate 1e-06\n",
      "input dimention 15\n",
      "batch size 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Train ERMS\",np.mean(NN.erms))\n",
    "#%%\n",
    "erms,out = NN.test(X_test,Y_test)\n",
    "print(\"Test ERMS\",erms)\n",
    "print(\"learning rate\",Lr)\n",
    "print(\"input dimention\",X_train.shape[1])\n",
    "print(\"batch size\",batch_size)\n",
    "plt.figure(1), plt.plot(NN.erms)\n",
    "plt.savefig(\"learning_curve.jpeg\")\n",
    "plt.figure(2), plt.plot(NN.final,'b'), plt.plot(Y_train,'r')\n",
    "plt.savefig(\"pred_train.jpeg\")\n",
    "plt.figure(3), plt.plot(out,'b'), plt.plot(Y_test,'r')\n",
    "plt.savefig(\"pred_test.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
